{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mediapipe\n",
    "%pip install tensorflow\n",
    "# Add other necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import audio\n",
    "\n",
    "# Initialize MediaPipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1)\n",
    "\n",
    "# Function to perform facial landmarking on an image\n",
    "def perform_facial_landmarking(image_path):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process image\n",
    "    results = face_mesh.process(rgb_image)\n",
    "\n",
    "    # Extract landmarks\n",
    "    landmarks = []\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for landmark in face_landmarks.landmark:\n",
    "                x, y, z = landmark.x, landmark.y, landmark.z\n",
    "                landmarks.append([x, y, z])\n",
    "\n",
    "    return np.array(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Folder containing FER2013 dataset images\n",
    "# dataset_folder = 'dataset/train'  # Adjust the folder path accordingly\n",
    "# csv_file = 'fer2013_landmarks.csv'\n",
    "\n",
    "# # Apply facial landmarking to all images in subfolders\n",
    "# facial_landmarks_data = []\n",
    "\n",
    "# # # Check if the CSV file already exists\n",
    "# # if not os.path.isfile(csv_file):\n",
    "# #     # Create a new CSV file with header if it doesn't exist\n",
    "# #     with open(csv_file, 'w', newline='') as file:\n",
    "# #         writer = csv.writer(file)\n",
    "# #         # column names are emotion, image path\n",
    "# #         header = ['emotion', 'image_path'] + [f'x_{i}' for i in range(468)]  # Assuming 468 landmarks\n",
    "# #         print(header)\n",
    "# #         writer.writerow(header)\n",
    "\n",
    "# # Append facial landmarks data to the CSV file\n",
    "# with open(csv_file, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write header\n",
    "#     header = ['emotion', 'image_path'] + [f'x_{i}' for i in range(468)]  # Assuming 468 landmarks\n",
    "#     print(header)\n",
    "#     writer.writerow(header)\n",
    "\n",
    "#     # Write data\n",
    "#     for emotion_folder in os.listdir(dataset_folder):\n",
    "#         emotion_path = os.path.join(dataset_folder, emotion_folder)\n",
    "#         print('Processing emotion:', emotion_folder)\n",
    "#         if os.path.isdir(emotion_path):\n",
    "#             for image_file in os.listdir(emotion_path):\n",
    "#                 image_path = os.path.join(emotion_path, image_file)\n",
    "#                 landmarks = perform_facial_landmarking(image_path)\n",
    "#                 print('landmarks: ', landmarks)\n",
    "\n",
    "#                 # Flatten the list of landmarks and group by 3 (x, y, z)\n",
    "#                 flattened_landmarks = [item for sublist in landmarks for item in sublist]\n",
    "#                 # grouped_landmarks = [flattened_landmarks[i:i+3] for i in range(0, len(flattened_landmarks), 3)]\n",
    "\n",
    "#                 # Append data to CSV\n",
    "#                 row = [emotion_folder, image_path] + flattened_landmarks\n",
    "#                 writer.writerow(row)\n",
    "#                 print('CSV Row:', row)  # Print the CSV row\n",
    "\n",
    "\n",
    "#                 # Open CSV in read mode to print its content\n",
    "#                 # with open(csv_file, 'r', newline='') as read_file:\n",
    "#                 #     csv_reader = csv.reader(read_file)\n",
    "#                 #     csv_content = list(csv_reader)\n",
    "#                 #     print('Current CSV Content:', csv_content)\n",
    "\n",
    "\n",
    "# # for emotion_folder in os.listdir(dataset_folder):\n",
    "# #     emotion_path = os.path.join(dataset_folder, emotion_folder)\n",
    "# #     print('Processing emotion:', emotion_folder)\n",
    "# #     if os.path.isdir(emotion_path):\n",
    "# #         for image_file in os.listdir(emotion_path):\n",
    "# #             image_path = os.path.join(emotion_path, image_file)\n",
    "# #             landmarks = perform_facial_landmarking(image_path)\n",
    "# #             print(landmarks)  # x y z\n",
    "#             # facial_landmarks_data.append({'landmarks': landmarks.tolist(), 'emotion': emotion_folder, 'image_path': image_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LANDMARKS = 468  # According to MediaPipe FaceMesh documentation\n",
    "\n",
    "# Folder containing FER2013 dataset images\n",
    "dataset_folder = 'dataset/train'  # Adjust the folder path accordingly\n",
    "csv_file = 'fer2013_landmarks.csv'\n",
    "\n",
    "# Apply facial landmarking to all images in subfolders\n",
    "facial_landmarks_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Check if the CSV file already exists\n",
    "# if not os.path.isfile(csv_file):\n",
    "#     # Create a new CSV file with header if it doesn't exist\n",
    "#     with open(csv_file, 'w', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         # column names are emotion, image path\n",
    "#         header = ['emotion', 'image_path'] + [f'x_{i}' for i in range(468)]  # Assuming 468 landmarks\n",
    "#         print(header)\n",
    "#         writer.writerow(header)\n",
    "\n",
    "# Append facial landmarks data to the CSV file\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write header\n",
    "    coordinate_columns = [f'{axis}{i+1}' for i in range(468) for axis in ['x', 'y', 'z']]\n",
    "    header = ['emotion', 'image_path'] + coordinate_columns\n",
    "    print(header)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # Write data\n",
    "    for emotion_folder in os.listdir(dataset_folder):\n",
    "        emotion_path = os.path.join(dataset_folder, emotion_folder)\n",
    "        print('Processing emotion:', emotion_folder)\n",
    "        if os.path.isdir(emotion_path):\n",
    "            for image_file in os.listdir(emotion_path):\n",
    "                image_path = os.path.join(emotion_path, image_file)\n",
    "                landmarks = perform_facial_landmarking(image_path)\n",
    "                print('landmarks: ', landmarks)\n",
    "\n",
    "                # Flatten the list of landmarks and group by 3 (x, y, z)\n",
    "                flattened_landmarks = [item for sublist in landmarks for item in sublist]\n",
    "                # grouped_landmarks = [flattened_landmarks[i:i+3] for i in range(0, len(flattened_landmarks), 3)]\n",
    "\n",
    "                # Append data to CSV\n",
    "                row = [emotion_folder, image_path] + flattened_landmarks\n",
    "                writer.writerow(row)\n",
    "                print('CSV Row:', row)  # Print the CSV row\n",
    "\n",
    "\n",
    "                # Open CSV in read mode to print its content\n",
    "                # with open(csv_file, 'r', newline='') as read_file:\n",
    "                #     csv_reader = csv.reader(read_file)\n",
    "                #     csv_content = list(csv_reader)\n",
    "                #     print('Current CSV Content:', csv_content)\n",
    "\n",
    "\n",
    "# for emotion_folder in os.listdir(dataset_folder):\n",
    "#     emotion_path = os.path.join(dataset_folder, emotion_folder)\n",
    "#     print('Processing emotion:', emotion_folder)\n",
    "#     if os.path.isdir(emotion_path):\n",
    "#         for image_file in os.listdir(emotion_path):\n",
    "#             image_path = os.path.join(emotion_path, image_file)\n",
    "#             landmarks = perform_facial_landmarking(image_path)\n",
    "#             print(landmarks)  # x y z\n",
    "            # facial_landmarks_data.append({'landmarks': landmarks.tolist(), 'emotion': emotion_folder, 'image_path': image_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## UPDATE LANDMARKS\n",
    "\n",
    "# with open(csv_file, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write header\n",
    "#     header = ['emotion', 'image_path'] + [f'x{i+1}' for i in range(468)] + [f'y{i+1}' for i in range(468)] + [f'z{i+1}' for i in range(468)]  # Assuming 468 landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(facial_landmarks_data)\n",
    "\n",
    "# Convert the result into a DataFrame\n",
    "landmarks_df = pd.DataFrame(facial_landmarks_data)\n",
    "\n",
    "# Save the DataFrame with facial landmarks, emotions, and image paths to a CSV file\n",
    "landmarks_df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('landmarked_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the data\n",
    "X = df.drop('emotion_label', axis=1).values\n",
    "y = df['emotion_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
